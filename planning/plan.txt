## 1. Executive Summary
WordWise AI (Marketing Manager Edition) is a web-based writing assistant that delivers real-time, on-brand copy improvements for B2B SaaS marketers.  The MVP will provide an authenticated rich-text editor that surfaces GPT-4o–powered grammar, tone, persuasion, and readability suggestions on highlighted text, tracks acceptance analytics, and lets users manage a single brand-voice profile.  The goal is a deploy-ready demo in seven days, prioritising fast suggestion latency (≤ 1.5 s) and ≥ 85 % accuracy.

## 2. Technical Architecture Overview
```mermaid
flowchart TD
  subgraph Browser (Vercel)
    A[React 18 + Vite + Tailwind UI]-->B[Zustand Store]
    A-->C[Editor (TipTap)]
  end
  C--WS JSON-->E((Supabase Realtime))
  C--REST-->F[(Supabase REST API)]
  C--RPC-->G[Edge Function: gptSuggest]
  G--HTTPS-->H(OpenAI GPT-4o)
  F--SQL-->I[(Postgres)]
  B--charts-->J[Analytics Dashboard]
```
• **Frontend**: React 18, TypeScript, Vite for rapid dev; TipTap editor (ProseMirror) for rich-text + inline widgets; Zustand for state; TailwindCSS for styling.  Hosted on Vercel for preview URLs & edge CDN.
• **Backend**: Supabase provides Postgres, Auth, Realtime, and Edge Functions (Deno).  Eliminates custom servers and accelerates setup.
• **AI**: Edge Function `gptSuggest` calls OpenAI GPT-4o with crafted prompts; keeps API keys server-side.
• **Data**: Postgres tables `users`, `documents`, `suggestions`, `analytics` with RLS rules.

## 3. Data Model & Schemas
```sql
-- users
auth.users handled by Supabase

-- brand profile (one-to-one)
CREATE TABLE profiles (
  user_id uuid PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
  tone text DEFAULT 'friendly',
  reading_level text DEFAULT '8th grade',
  banned_words text[] DEFAULT '{}'
);

-- documents
CREATE TABLE documents (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id uuid REFERENCES auth.users(id) ON DELETE CASCADE,
  title text NOT NULL,
  content text NOT NULL,
  created_at timestamptz DEFAULT now(),
  updated_at timestamptz DEFAULT now()
);
CREATE INDEX ON documents(user_id);

-- suggestions
CREATE TYPE suggestion_type AS ENUM ('grammar','tone','persuasion','concise','headline','readability','vocab','ab_test');
CREATE TABLE suggestions (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  doc_id uuid REFERENCES documents(id) ON DELETE CASCADE,
  start_idx int, end_idx int,
  type suggestion_type,
  original text,
  suggestion text,
  explanation text,
  confidence numeric,
  accepted boolean DEFAULT false,
  created_at timestamptz DEFAULT now()
);
CREATE INDEX ON suggestions(doc_id);

-- analytics (batch nightly)
CREATE TABLE analytics (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id uuid,
  metric text,
  value numeric,
  ts timestamptz DEFAULT now()
);
```

## 4. API & Integration Contracts
| # | Method | Path | Request | Response | Auth |
|---|--------|------|---------|----------|------|
|1|POST|/rpc/gptSuggest|`{ docId, text, type }`|`[{start, end, suggestion, explanation, confidence}]`|JWT|
|2|GET|/rest/v1/documents| |`[Document]`|JWT|
|3|POST|/rest/v1/documents|`{title, content}`|`Document`|JWT|
|4|PATCH|/rest/v1/documents/:id|`{content}`|`Document`|JWT|
|5|GET|/rest/v1/suggestions?doc_id=eq.:id| |`[Suggestion]`|JWT|
|6|PATCH|/rest/v1/suggestions/:id|`{accepted:true}`|`Suggestion`|JWT|
|7|GET|/rest/v1/analytics?user_id=eq.:uid| |`[Analytics]`|JWT|
|8|POST|/auth/v1/token|Supabase handled|JWT|—|

**AI Prompt (gptSuggest)**
```json
{
  "system": "You are WordWise, an AI writing assistant…",
  "user": "<TEXT_TO_ANALYZE>",
  "brandTone": "friendly",
  "task": "grammar,tone,etc",
  "constraints": {"max_words":2000}
}
```
Expected latency ≤1.5 s, returns structured JSON suggestions.

## 5. Epic & Milestone Breakdown (7-Day Hack)
| Day | Goals & Deliverables | Stories (AC) | Key Tasks | Effort |
|-----|---------------------|--------------|-----------|--------|
|1|Repo scaffolding, Supabase project, auth flow, layout shell|Login works, test-user button logs in.|`pnpm create vite`, Tailwind config, Supabase init, RLS rules|S|
|2|Document CRUD|User can create, open, save docs.|TipTap setup, REST hooks, optimistic save|M|
|3|Grammar & spelling suggestions|Highlight text, call `gptSuggest`, show card.|Edge Function, prompt, inline UI|L|
|4|Tone & persuasion|Same flow as Day 3 for new types.|Prompt tweaks, card icons|M|
|5|Headline & readability + analytics dashboard|Chart displays % accepted.|`readability-score` util, Recharts dashboard|M|
|6|A/B CTA generator, polish, accessibility pass|User can request two variants.|Condensed prompt, export to Markdown/HTML/Text|M|
|7|Testing, CI, deploy to Vercel, demo video|All tests pass, prod URL live.|Playwright E2E, GitHub Actions, recording|S|

## 6. Detailed Task Board
1. **Set up repo & tooling** – ESLint, Prettier, Husky (DoD: `npm run lint` passes) – S
2. **Configure Supabase Auth** – Email/password + test button – S
3. **Implement TipTap editor wrapper** – Renders rich-text, exposes selected text – M
4. **Document CRUD hooks** – `useDocuments` (React Query) – S
5. **Edge Function: gptSuggest** – Validate input, call OpenAI, map output – L
6. **Inline Suggestion Card component** – Accept/Reject buttons emit events – M
7. **Analytics batch job** – SQL roll-up nightly using Supabase cron – S
8. **Dashboard page** – Charts from `analytics` table – M
9. **Settings page** – Update profile.tone etc. – S
10. **Export modal** – Download .md, .html, .txt – S
11. **Playwright scenarios** – Login, suggest, accept – M
12. **GitHub Actions CI** – Lint, test, deploy – S

## 7. AI/ML Component Specification
• **Model**: OpenAI GPT-4o via REST.
• **Prompt Engineering**: JSON schema enforced with system role; include brand tone and task type.
• **Evaluation**: Acceptance-rate metric and random manual review on 50 samples.
• **Latency**: Edge Function in same region as OpenAI; budget 500 ms processing, 1 s network round-trip.

## 8. Testing Strategy
| Layer | Tool | Scope | Target Coverage |
|-------|------|-------|-----------------|
|Unit|Vitest|Utils, hooks|80 % lines|
|Integration|@testing-library/react|Editor ↔ suggest card|70 %|
|E2E|Playwright|Auth, doc CRUD, suggestion flow|Critical paths pass|
|Load|k6|Edge Function 50 req/s sustained|<1.5 s p50|

## 9. DevOps & Deployment Pipeline
1. **Branching**: `main` → prod; feature branches PR-merged.
2. **CI**: GitHub Actions – install, lint, test, build.
3. **CD**: Vercel Preview for PRs; prod deploy on main.
4. **Infra-as-Code**: `supabase/config.toml` tracked; secrets via Vercel & Supabase dashboards.
5. **Monitoring**: Vercel analytics, Supabase logs, OpenAI error hooks; Slack alerts.

## 10. Risk Register & Mitigations
| Risk | Impact | Likelihood | Mitigation |
|------|--------|-----------|------------|
|OpenAI latency spike|User frustration|Med|Cache last 5 prompts; show skeleton UI|
|Rate limits|Feature outage|Low|Retry w/ exponential back-off|
|Editor complexity|Schedule slip|Med|Leverage TipTap starter kit|
|Analytics query cost|Cost overrun|Low|Batch nightly aggregates|

## 11. Success Metrics Alignment
| PRD Metric | Plan Checkpoint |
|------------|----------------|
|≥ 85 % grammar accuracy|Manual review sample Day 3 & Day 6|
|≤ 1.5 s latency|k6 load test in CI|
|≥ 80 % suggestions accepted|Dashboard query post-demo|

## 12. Next Steps & Open Questions
1. Confirm OpenAI API budget & key provisioning.
2. Decide readability formula (FK, ARI?).
3. Stakeholder sign-off on UI mockups.

## 13. Clarifying Questions
None outstanding.

## 14. Detailed On-Ramp Task List (Junior-Friendly)
Follow the numbered *Main Steps* in order.  Each main step is broken into **Sub-Tasks** so you always know:
1. **Goal** – why you are doing it.  
2. **Implementation** – exact commands/files/lines to touch.  
3. **Test** – how to prove success.  

---

### Main Step 0 — Prepare Local Docker Environment

**0.1 Install Docker Desktop**  
• Goal Install container runtime for consistent dev setup.  
• Implementation Download Docker Desktop for macOS → drag to Applications → launch once.  
• Test Run `docker --version` in Terminal → output shows a version number.

**0.2 Create Dockerfile**  
• Goal Define how the project image is built.  
• Implementation Create `Dockerfile` at project root with:
```Dockerfile
FROM node:20-alpine
WORKDIR /usr/src/app
COPY package.json pnpm-lock.yaml ./
RUN corepack enable && corepack prepare pnpm@8.15.0 --activate && pnpm install
COPY . .
EXPOSE 5173
CMD ["pnpm","dev","--host"]
```
• Test `docker build -t wordwise-dev .` completes with **0 errors**.

**0.3 Write .dockerignore**  
• Goal Keep image small & builds fast.  
• Implementation Add:
```
node_modules
.vscode
dist
.env
```
• Test Re-build image; build context size < 1 MB (displayed at start of build).

**0.4 Compose File for Web Service**  
• Goal One-command startup.  
• Implementation Create `docker-compose.yml`:
```yml
version: "3.9"
services:
  web:
    build: .
    ports:
      - "5173:5173"
    volumes:
      - .:/usr/src/app
      - web_node_modules:/usr/src/app/node_modules
volumes:
  web_node_modules:
```
• Test `docker compose up` → browser to http://localhost:5173 shows Vite page.

---

### Main Step 1 — Setup Local Supabase

**1.1 Install Supabase CLI**  
• Goal Manage local database & Edge Functions.  
• Implementation `brew install supabase/tap/supabase` (mac) or follow docs.  
• Test `supabase --version` outputs version.

**1.2 Initialise Supabase Project**  
• Goal Generate config/migrations folder.  
• Implementation `supabase init` inside repo.  
• Test `.supabase` folder appears with `config.toml`.

**1.3 Add Supabase to Docker Compose**  
• Goal Start Postgres & Realtime containers locally.  
• Implementation Append to `docker-compose.yml`:
```yml
  supabase:
    image: supabase/postgres:15
    ports:
      - "54322:5432"
      - "54323:5433"
    volumes:
      - supa_data:/var/lib/postgresql/data
volumes:
  web_node_modules:
  supa_data:
```
• Test `docker compose up` logs: *database system is ready to accept connections*.

---

### Main Step 2 — Source Control Hygiene

**2.1 Git Ignore Secrets**  
• Goal Prevent accidental commit of secrets.  
• Implementation Add `.env` to `.gitignore`.  
• Test `git status` shows `.env` file as **untracked and ignored**.

**2.2 Commit Example Env File**  
• Goal Share required variables without secrets.  
• Implementation Create `.env.example` listing `SUPABASE_URL`, `SUPABASE_ANON_KEY`, etc.  
• Test New hire can copy file → rename to `.env` → app boots.

---

### Main Step 3 — Tooling & Quality Gates

**3.1 Add ESLint & Prettier**  
• Goal Catch bugs & enforce style.  
• Implementation `pnpm add -D eslint prettier eslint-config-prettier @typescript-eslint/parser @typescript-eslint/eslint-plugin` → create `.eslintrc.json` per template.  
• Test Run `pnpm lint` → "0 problems".

**3.2 Husky Pre-Commit**  
• Goal Block commits that fail lint.  
• Implementation `npx husky-init && pnpm husky add .husky/pre-commit "pnpm lint"`.  
• Test Insert bad code (`var x = 1`) → `git commit` fails with ESLint error.

---

### Main Step 4 — Frontend Scaffold

**4.1 Create Vite React App**  
• Goal Baseline React+TS project.  
• Implementation `pnpm create vite@latest client --template react-ts` then move into root or adjust paths.  
• Test `docker compose up` shows "Vite + React" page.

**4.2 Add Tailwind**  
• Goal Utility CSS.  
• Implementation `pnpm add -D tailwindcss postcss autoprefixer && npx tailwindcss init -p` → update `tailwind.config.ts`.

• Test Place `<div class="bg-red-500 h-4 w-4"/>`; red square appears.

**4.3 Add React Router**  
• Goal Multi-page SPA.  
• Implementation `pnpm add react-router-dom` → create routes `/login`, `/editor`, `/dashboard`, `/settings`.  
• Test Manual URL change to `/login` shows component.

**4.4 Navbar Component**  
• Goal Global nav except on login.  
• Implementation Create `Navbar.tsx` with Tailwind flex; hide when `pathname === '/login'`.  
• Test Navbar present on `/editor`, gone on `/login`.

---

### Main Step 5 — Supabase Auth

**5.1 Supabase Client File**  
• Goal Reusable authenticated client.  
• Implementation `supabaseClient.ts` reading env vars and exporting `createClient`.  
• Test `console.log(supabase.auth)` shows functions available.

**5.2 Email/Password Login Form**  
• Goal Allow user authentication.  
• Implementation Build `Login.tsx` with email/password fields and submit handler calling `supabase.auth.signInWithPassword`.  
• Test Correct creds redirect to `/editor`; wrong creds show Supabase error.

**5.3 Seed Test User**  
• Goal Quick QA account.  
• Implementation `supabase auth sign-up --email test@acme.com --password secret` via CLI.  
• Test Login with test account succeeds.

---

### Main Step 6 — Rich Text Editor

**6.1 Install TipTap**  
• Goal Rich text abilities.  
• Implementation `pnpm add @tiptap/react @tiptap/starter-kit`; mount in `Editor.tsx`.  
• Test Typing text appears; Cmd+B toggles bold.

**6.2 Basic Toolbar**  
• Goal Formatting controls.  
• Implementation Add bold, italic, heading buttons with onClick commands.  
• Test Click Bold button → selected text becomes bold.

**6.3 Auto-Save Hook**  
• Goal Prevent data loss.  
• Implementation `useEffect` debounce editor content and call `saveDocument` every 5 s.  
• Test Open Network tab → PATCH request fires every 5 s while editing.

**6.4 Upload .txt File**  
• Goal Import existing content.  
• Implementation `<input type='file' accept='.txt' onChange={readFile}>`.  
• Test Selecting a text file fills the editor with its content.

**6.5 Export Modal**  
• Goal Download work.  
• Implementation Add HeadlessUI `Dialog` with buttons: Markdown, HTML, Text; generate files and trigger download.  
• Test Choose Markdown → file downloads and content matches editor.

---

### Main Step 7 — Backend: Documents & Suggestions Tables

**7.1 Create Documents Table Migration**  
• Goal Store user docs.  
• Implementation Add SQL file per Section 3; run `supabase db push`.  
• Test Table appears in Supabase dashboard.

**7.2 CRUD Hook for Documents**  
• Goal Abstract DB operations.  
• Implementation Write `useDocuments.ts` using Supabase JS `insert`, `update`, `select`.  
• Test Create doc → refresh → doc persists.

**7.3 Create Suggestions Table Migration**  
• Goal Store AI feedback.  
• Implementation Create migration for `suggestions` (fields per Section 3).  
• Test Table visible in dashboard.

---

### Main Step 8 — Edge Function & GPT Integration

**8.1 Edge Function Scaffold**  
• Goal Serverless endpoint.  
• Implementation `supabase functions new gptSuggest --no-verify-jwt`.  
• Test `supabase functions serve` returns 200 on GET.

**8.2 Prompt Builder Utility**  
• Goal Consistent OpenAI prompt.  
• Implementation `buildPrompt.ts` constructing JSON with text, type, tone.  
• Test Vitest snapshot matches expected JSON.

**8.3 Call OpenAI**  
• Goal Get suggestions.  
• Implementation Inside Edge Function, `await fetch('https://api.openai.com/v1/chat/completions', …)` parse response.  
• Test `curl` function with sample text returns suggestions.

**8.4 Toolbar Suggest Button**  
• Goal Trigger suggestion flow.  
• Implementation Add button that POSTs selection to Edge Function; store result.  
• Test Console shows suggestion array.

**8.5 Inline Suggestion Card UI**  
• Goal Display feedback.  
• Implementation Create floating card with Accept / Dismiss.  
• Test Accept replaces text; Dismiss removes card.

**8.6 Persist Suggestion Rows**  
• Goal Analytics tracking.  
• Implementation Insert row in `suggestions` table; update on accept.  
• Test Dashboard table shows new row with `accepted=true`.

---

### Main Step 9 — Advanced Suggestion Types
(Sub-tasks repeat pattern: Goal • Implementation • Test)

**9.1 Tone & Persuasion**  
• Goal Provide tone/persuasion improvements.  
• Implementation Dropdown in toolbar sets `type`; prompt builder includes it.  
• Test Selecting "Tone" returns tone suggestions.

**9.2 Headline Optimizer**  
• Goal Improve titles.  
• Implementation Enable button when selection ≤120 chars.  
• Test Button disabled for longer text; enabled for short headline.

**9.3 Readability Badge**  
• Goal Show FK grade.  
• Implementation Compute score after save; badge bottom-right colored.  
• Test Grade changes as text changes.

**9.4 Vocabulary Variation**  
• Goal Avoid repetition.  
• Implementation "Vary" button when ≥3 words; `type:'vocab'`.  
• Test Card returns synonyms.

**9.5 A/B CTA Generator**  
• Goal Improve CTAs.  
• Implementation Side drawer button appears when selection contains trigger words; prompt returns two variants.  
• Test Variants A & B appear and can be inserted.

---

### Main Step 10 — Analytics & Dashboard

**10.1 Scheduled Analytics Job**  
• Goal Aggregate data nightly.  
• Implementation SQL function + Supabase cron 02:00 UTC.  
• Test Next day `analytics` table has new rows.

**10.2 Dashboard Charts**  
• Goal Visual insight.  
• Implementation Use TanStack Charts to render line (% accepted) + bar (by type).  
• Test Charts show data; tooltips display values.

**10.3 Auto-Refresh**  
• Goal Realtime-ish updates.  
• Implementation `useQuery` with `refetchInterval:30000`.  
• Test Timestamp updates every 30 s.

---

### Main Step 11 — User Settings

**11.1 Settings Form**  
• Goal Let user set brand tone.  
• Implementation Create form with Tone select, Reading Level, Banned Words; save to `profiles`.  
• Test Toast "Profile updated" appears; DB row updated.

**11.2 Inject Profile in Prompt**  
• Goal Personalise suggestions.  
• Implementation Fetch profile on login; pass to prompt builder.  
• Test Network payload shows brandTone field.

---

### Main Step 12 — Realtime Collaboration Lite

**12.1 Subscribe to Document Changes**  
• Goal Sync tabs.  
• Implementation `supabase.channel('doc-<id>').on('postgres_changes', …)` update editor.  
• Test Edit in tab A → appears in tab B within 1 s.

**12.2 Presence Indicator**  
• Goal Show connection status.  
• Implementation Green dot when websocket open; gray when closed.  
• Test Disable wifi → dot turns gray; enable → green.

---

### Main Step 13 — Testing & QA

**13.1 Unit Tests**  
• Goal Check utility functions.  
• Implementation Set up Vitest; test readability and prompt builder.  
• Test `pnpm test` shows 100 % pass.

**13.2 End-to-End Tests**  
• Goal Ensure critical flow works.  
• Implementation Record Playwright script login → create doc → suggest → accept.  
• Test `npx playwright test` passes.

**13.3 Load Test**  
• Goal Validate latency target.  
• Implementation k6 script 50 req/s for 60 s.  
• Test Report p50 ≤1.5 s.

---

### Main Step 14 — CI/CD & Release

**14.1 GitHub Actions Pipeline**  
• Goal Automate quality gates & preview deploys.  
• Implementation Workflow: install → lint → unit → e2e → docker build → Vercel deploy preview.  
• Test Open PR has green checks and Preview URL comment.

**14.2 Production Release**  
• Goal Deploy on merge to `main`.  
• Implementation Protect `main`; configure Vercel prod branch.  
• Test Merge PR → Vercel dashboard shows Production build success.

---

### Main Step 15 — Demo Assets

**15.1 Seed Script**  
• Goal Populate demo data.  
• Implementation `seed.ts` inserting sample doc & suggestions via Supabase client.  
• Test Running `pnpm run seed` prints "Seed complete" and records visible.

**15.2 Loom Video**  
• Goal Marketing/demo artifact.  
• Implementation Record 2-min walk-through; add link to README.  
• Test Link opens video and plays.

---

_Check off every Sub-Task once its **Test** passes.  Completing all Main Steps delivers the MVP._
